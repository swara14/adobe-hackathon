from sentence_transformers import SentenceTransformer
SentenceTransformer('all-MiniLM-L6-v2').save('./MiniLM-local')


from sentence_transformers import SentenceTransformer, util
import fitz
import os
import json
from datetime import datetime

# Load local model
model = SentenceTransformer("MiniLM-local")

def get_all_text(doc):
    full_text = []
    for page_num in range(len(doc)):
        page = doc.load_page(page_num)
        text = page.get_text()
        full_text.append((page_num + 1, text))
    return full_text

def rank_relevant_sections(pages, persona, job, top_k=5):
    scores = []
    query = f"{persona}. {job}"
    for page_num, text in pages:
        chunks = text.split('\n\n')
        for chunk in chunks:
            if len(chunk.strip()) < 30:
                continue
            emb_chunk = model.encode(chunk, convert_to_tensor=True)
            emb_query = model.encode(query, convert_to_tensor=True)
            sim = util.cos_sim(emb_chunk, emb_query).item()
            scores.append({
                "document": "unknown.pdf",  # updated in main loop
                "page": page_num,
                "section_title": chunk.split('\n')[0][:100],
                "importance_rank": sim,
                "refined_text": chunk.strip()
            })
    return sorted(scores, key=lambda x: x["importance_rank"], reverse=True)[:top_k]

def save_json(data, path):
    with open(path, "w", encoding="utf-8") as f:
        json.dump(data, f, indent=2, ensure_ascii=False)

def main():
    input_dir = "input"
    output_dir = "output"
    os.makedirs(output_dir, exist_ok=True)

    # Define your persona & job
    persona = "PhD Researcher in Computational Biology"
    job = "Prepare a comprehensive literature review focusing on methodologies, datasets, and performance benchmarks"

    for fname in os.listdir(input_dir):
        if fname.lower().endswith(".pdf"):
            fpath = os.path.join(input_dir, fname)
            with fitz.open(fpath) as doc:
                pages = get_all_text(doc)
                ranked = rank_relevant_sections(pages, persona, job)
                for r in ranked:
                    r["document"] = fname
                    r["importance_rank"] = round(r["importance_rank"], 4)

                result = {
                    "metadata": {
                        "documents": [fname],
                        "persona": persona,
                        "job_to_be_done": job,
                        "timestamp": datetime.now().isoformat()
                    },
                    "extracted_sections": ranked
                }

                save_json(result, os.path.join(output_dir, fname.replace(".pdf", "_round1b.json")))
                print(f"Processed {fname}")

if __name__ == "__main__":
    main()
